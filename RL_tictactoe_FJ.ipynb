{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Introduction**  \n",
    "Explain RL  \n",
    "Explain value action  \n",
    "Refer to OOP  \n",
    "Refer to data science blog Jeremy Zhang & Richard Karl bill-the-bot  \n",
    "First let two computers play each other >> save policy >> play against human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries & modules\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class State**  \n",
    "The state of this game is the board state of both the agent and its opponent (agent or human). Characteristics:  \n",
    "- Initialise a 3x3 board with zeros indicating available positions   \n",
    "- Update positions with 1 if player 1 takes a move and -1 if player 2 takes a move  \n",
    "- The action is what positions a player can choose based on the current board state  \n",
    "- Reward is between 0 and 1 and is only given at the end of the game"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Board_rows = 3\n",
    "Board_cols = 3\n",
    "\n",
    "class State:\n",
    "    def __init__(self, p1, p2):\n",
    "        self.board = np.zeros((Board_rows, Board_cols))\n",
    "        self.p1 = p1\n",
    "        self.p2 = p2\n",
    "        self.isEnd = False\n",
    "        self.boardHash = None # Hash function to map data of arbitrary size to fixed-size values\n",
    "        self.playerSymbol = 1 # init p1 plays first\n",
    "        \n",
    "    # get unique hash of current board state\n",
    "    def getHash(self):\n",
    "        self.boardHash = str(self.board.reshape(Board_rows * Board_cols)) #reshape to str\n",
    "        return self.boardHash\n",
    "    \n",
    "    # check if one of players has 3 in a row\n",
    "    def winner(self):\n",
    "        # 3 in a row in row\n",
    "        for i in range(Board_rows):\n",
    "            if sum(self.board[i, :]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[i, :]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # 3 in a row in column\n",
    "        for i in range(Board_cols):\n",
    "            if sum(self.board[:, i]) == 3:\n",
    "                self.isEnd = True\n",
    "                return 1\n",
    "            if sum(self.board[:, i]) == -3:\n",
    "                self.isEnd = True\n",
    "                return -1\n",
    "        # 3 in a row in diagonal\n",
    "        diag_sum1 = sum([self.board[i, i] for i in range(Board_cols)])\n",
    "        diag_sum2 = sum([self.board[i, Board_cols - i - 1] for i in range(Board_cols)])\n",
    "        diag_sum = max(abs(diag_sum1), abs(diag_sum2))\n",
    "        if diag_sum == 3:\n",
    "            self.isEnd = True\n",
    "            if diag_sum1 == 3 or diag_sum2 == 3:\n",
    "                return 1\n",
    "            else:\n",
    "                return -1\n",
    "\n",
    "        # tie because of full board \n",
    "        if len(self.availablePositions()) == 0:\n",
    "            self.isEnd = True\n",
    "            return 0\n",
    "        # if game is at not end\n",
    "        self.isEnd = False\n",
    "        return None\n",
    "    \n",
    "    # check the available positions\n",
    "    def availablePositions(self):\n",
    "        positions = []\n",
    "        for i in range(Board_rows):\n",
    "            for j in range(Board_cols):\n",
    "                if self.board[i, j] == 0:\n",
    "                    positions.append((i, j))  # need to be tuple of column and row\n",
    "        return positions\n",
    "\n",
    "    # add symbol to board if to action taken\n",
    "    def updateState(self, position):\n",
    "        self.board[position] = self.playerSymbol\n",
    "        self.playerSymbol = -1 if self.playerSymbol == 1 else 1 # switch to another player\n",
    "\n",
    "    # if a game ends\n",
    "    def giveReward(self):\n",
    "        result = self.winner()\n",
    "        \n",
    "        # give reward to player to be able to backpropagate\n",
    "        if result == 1:\n",
    "            self.p1.feedReward(1)\n",
    "            self.p2.feedReward(0)\n",
    "        elif result == -1:\n",
    "            self.p1.feedReward(0)\n",
    "            self.p2.feedReward(1)\n",
    "        else:\n",
    "            self.p1.feedReward(0.1) #TO DO check why this is lower....\n",
    "            self.p2.feedReward(0.5)\n",
    "\n",
    "    # reset board after games is ended\n",
    "    def reset(self):\n",
    "        self.board = np.zeros((Board_rows, Board_cols))\n",
    "        self.boardHash = None\n",
    "        self.isEnd = False\n",
    "        self.playerSymbol = 1\n",
    "\n",
    "    # gameplay for 2 agents playing each other    \n",
    "    def play(self, rounds=100):\n",
    "        for i in range(rounds):\n",
    "            if i % 1000 == 0:\n",
    "                print(\"Rounds {}\".format(i))\n",
    "            while not self.isEnd:\n",
    "                # Player 1\n",
    "                positions = self.availablePositions()\n",
    "                p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                # Take action and update board state\n",
    "                self.updateState(p1_action)\n",
    "                board_hash = self.getHash()\n",
    "                self.p1.addState(board_hash)\n",
    "                # check board status if it is end\n",
    "\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    # self.showBoard()\n",
    "                    # ended with p1 either win or draw\n",
    "                    self.giveReward()\n",
    "                    self.p1.reset()\n",
    "                    self.p2.reset()\n",
    "                    self.reset()\n",
    "                    break\n",
    "\n",
    "                else:\n",
    "                    # Player 2\n",
    "                    positions = self.availablePositions()\n",
    "                    p2_action = self.p2.chooseAction(positions, self.board, self.playerSymbol)\n",
    "                    self.updateState(p2_action)\n",
    "                    board_hash = self.getHash()\n",
    "                    self.p2.addState(board_hash)\n",
    "\n",
    "                    win = self.winner()\n",
    "                    if win is not None:\n",
    "                        # self.showBoard()\n",
    "                        # ended with p2 either win or draw\n",
    "                        self.giveReward()\n",
    "                        self.p1.reset()\n",
    "                        self.p2.reset()\n",
    "                        self.reset()\n",
    "                        break\n",
    "\n",
    "    # gameplay agent vs human\n",
    "    def playhuman(self):\n",
    "        while not self.isEnd:\n",
    "            # Agent (player 1)\n",
    "            positions = self.availablePositions()\n",
    "            p1_action = self.p1.chooseAction(positions, self.board, self.playerSymbol)\n",
    "            # Take action and update board state\n",
    "            self.updateState(p1_action)\n",
    "            self.showBoard()\n",
    "            # check board status if it is end\n",
    "            win = self.winner()\n",
    "            if win is not None:\n",
    "                if win == 1:\n",
    "                    print(self.p1.name, \"wins!\")\n",
    "                else:\n",
    "                    print(\"tie!\")\n",
    "                self.reset()\n",
    "                break\n",
    "\n",
    "            else:\n",
    "                # Player 2\n",
    "                positions = self.availablePositions()\n",
    "                p2_action = self.p2.chooseAction(positions)\n",
    "\n",
    "                self.updateState(p2_action)\n",
    "                self.showBoard()\n",
    "                win = self.winner()\n",
    "                if win is not None:\n",
    "                    if win == -1:\n",
    "                        print(self.p2.name, \"wins!\")\n",
    "                    else:\n",
    "                        print(\"tie!\")\n",
    "                    self.reset()\n",
    "                    break\n",
    "    \n",
    "    # gameplay agent vs human\n",
    "    def showBoard(self):\n",
    "        # p1: x  p2: o\n",
    "        for i in range(0, Board_rows):\n",
    "            print('-------------')\n",
    "            out = '| '\n",
    "            for j in range(0, Board_cols):\n",
    "                if self.board[i, j] == 1:\n",
    "                    token = 'x'\n",
    "                if self.board[i, j] == -1:\n",
    "                    token = 'o'\n",
    "                if self.board[i, j] == 0:\n",
    "                    token = ' '\n",
    "                out += token + ' | '\n",
    "            print(out)\n",
    "        print('-------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class Player**  \n",
    "A player class which represents our agent, and the player is able to:  \n",
    "- Choose actions based on current action-value estimation of the states\n",
    "- Record all the states of the game\n",
    "- Update states-value estimation after each game\n",
    "- Save and load the policy to be able to use it to play against human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Player:\n",
    "    def __init__(self, name, exp_rate=0.3):\n",
    "        self.name = name\n",
    "        self.states = []  # record all positions taken\n",
    "        self.lr = 0.2\n",
    "        self.exp_rate = exp_rate\n",
    "        self.decay_gamma = 0.9 # standard number\n",
    "        self.states_value = {}  # dictionary  state -> value\n",
    "\n",
    "    # DOET DIT IETS?\n",
    "    def getHash(self, board):\n",
    "        boardHash = str(board.reshape(Board_rows * Board_cols))\n",
    "        return boardHash\n",
    "\n",
    "    def chooseAction(self, positions, current_board, symbol):\n",
    "        if np.random.uniform(0, 1) <= self.exp_rate:\n",
    "            # take random action\n",
    "            idx = np.random.choice(len(positions))\n",
    "            action = positions[idx]\n",
    "        else:\n",
    "            value_max = -999\n",
    "            for p in positions:\n",
    "                next_board = current_board.copy()\n",
    "                next_board[p] = symbol\n",
    "                next_boardHash = self.getHash(next_board)\n",
    "                value = 0 if self.states_value.get(next_boardHash) is None else self.states_value.get(next_boardHash)\n",
    "                # print(\"value\", value)\n",
    "                if value >= value_max:\n",
    "                    value_max = value\n",
    "                    action = p\n",
    "        # print(\"{} takes action {}\".format(self.name, action))\n",
    "        return action\n",
    "\n",
    "    # append a hash state\n",
    "    def addState(self, state):\n",
    "        self.states.append(state) # add state to empty list\n",
    "\n",
    "    # at the end of game, backpropagate and update states value\n",
    "    def feedReward(self, reward):\n",
    "        for st in reversed(self.states):\n",
    "            if self.states_value.get(st) is None:\n",
    "                self.states_value[st] = 0\n",
    "            self.states_value[st] += self.lr * (self.decay_gamma * reward - self.states_value[st])\n",
    "            reward = self.states_value[st]\n",
    "\n",
    "    def reset(self):\n",
    "        self.states = []\n",
    "\n",
    "    def savePolicy(self):\n",
    "        output = open('policy_p1.pkl', 'wb')\n",
    "        pickle.dump(self.states_value, output)\n",
    "        output.close()\n",
    "    \n",
    "    def loadPolicy(self, file):\n",
    "        pkl_file = open(file, 'rb')\n",
    "        self.states_value = pickle.load(pkl_file)\n",
    "        pkl_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Class HumanPlayer**  \n",
    "A seperate class for a human player that can take actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanPlayer:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def chooseAction(self, positions):\n",
    "        while True:\n",
    "            row = int(input(\"Input your action row:\"))\n",
    "            col = int(input(\"Input your action col:\"))\n",
    "            action = (row, col)\n",
    "            if action in positions:\n",
    "                return action"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train game**  \n",
    "During training, the process for each player/agent is:\n",
    "- Look for available positions\n",
    "- Choose action\n",
    "- Update board state and add the action to playerâ€™s states\n",
    "- Judge if reach the end of the game and give reward accordingly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training...\n",
      "Rounds 0\n",
      "Rounds 1000\n",
      "Rounds 2000\n",
      "Rounds 3000\n",
      "Rounds 4000\n",
      "Rounds 5000\n",
      "Rounds 6000\n",
      "Rounds 7000\n",
      "Rounds 8000\n",
      "Rounds 9000\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # training\n",
    "    p1 = Player(\"p1\")\n",
    "    p2 = Player(\"p2\")\n",
    "\n",
    "    st = State(p1, p2)\n",
    "    print(\"training...\")\n",
    "    st.play(10000)\n",
    "    p1.savePolicy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Play with human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#p1.states_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#st.availablePositions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input your action row: 0\n",
      "Input your action col: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| x |   |   | \n",
      "-------------\n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| x |   | x | \n",
      "-------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input your action row: 2\n",
      "Input your action col: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   |   |   | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "-------------\n",
      "|   | o |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Input your action row: 01\n",
      "Input your action col: 1\n",
      "Input your action row: 0\n",
      "Input your action col: 1\n",
      "Input your action row: 0\n",
      "Input your action col: 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "| o | o |   | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "-------------\n",
      "| o | o | x | \n",
      "-------------\n",
      "|   | x |   | \n",
      "-------------\n",
      "| x | o | x | \n",
      "-------------\n",
      "computer wins!\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    \n",
    "    p1 = Player('computer', exp_rate=0)\n",
    "    p1.loadPolicy('policy_p1.pkl')\n",
    "\n",
    "    p2 = HumanPlayer('human')\n",
    "\n",
    "    st = State(p1, p2)\n",
    "    st.playhuman()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
